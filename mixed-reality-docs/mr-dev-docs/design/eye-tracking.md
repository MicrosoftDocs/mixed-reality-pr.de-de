---
title: Eyetracking – Blickverfolgung
description: Erfahren Sie mehr über eye tracking for HoloLens 2 und die neuen Ebenen des menschlichen Verständnisses, wenn es holografische Erfahrungen bietet.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: Eyetracking, Mixed Reality, Eingabe, Anvieren mit den Augen, Kalibrierung, Mixed Reality-Headset, Windows Mixed Reality-Headset, Virtual Reality-Headset, HoloLens, MRTK, Mixed Reality Toolkit, Absicht, Aktionen
ms.openlocfilehash: b76fd2e05999e5807156714fcdf12ca2863501bc
ms.sourcegitcommit: 8f141a843bcfc57e1b18cc606292186b8ac72641
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 05/19/2021
ms.locfileid: "110196505"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="57bec-104">Blickverfolgung auf HoloLens 2</span><span class="sxs-lookup"><span data-stu-id="57bec-104">Eye tracking on HoloLens 2</span></span>

![Eyetracking-Demo in MRTK](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="57bec-106">HoloLens 2 ermöglicht ein neues Maß an Kontext und menschlichem Verständnis innerhalb der holografischen Benutzeroberfläche, indem Entwicklern die Möglichkeit zur Verfügung steht, Informationen dazu zu verwenden, was der Benutzer betrachtet.</span><span class="sxs-lookup"><span data-stu-id="57bec-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="57bec-107">Auf dieser Seite wird erläutert, wie Entwickler von der Eyetracking für verschiedene Anwendungsfälle profitieren können und worauf sie beim Entwerfen von Benutzerinteraktionen achten müssen, die auf anvingerten Blicken basieren.</span><span class="sxs-lookup"><span data-stu-id="57bec-107">This page explains how developers can benefit from eye tracking for various use cases, and what to look for when designing eye-gaze-based user interactions.</span></span> 

<span data-ttu-id="57bec-108">Die Eyetracking-API wurde mit Blick auf den Datenschutz eines Benutzers entwickelt und vermeidet die Übergabe identifizierbarer Informationen, insbesondere biometrischer Daten.</span><span class="sxs-lookup"><span data-stu-id="57bec-108">Eye tracking API has been designed with a user’s privacy in mind, avoiding passing any identifiable information, particularly any biometrics.</span></span> <span data-ttu-id="57bec-109">Für Eyetracking-fähige Anwendungen muss der Benutzer der App die Berechtigung zum Verwenden von Eyetrackinginformationen erteilen.</span><span class="sxs-lookup"><span data-stu-id="57bec-109">For eye-tracking capable applications, the user needs to grant app permission to use eye tracking information.</span></span>

### <a name="device-support"></a><span data-ttu-id="57bec-110">Geräteunterstützung</span><span class="sxs-lookup"><span data-stu-id="57bec-110">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="57bec-111"><strong>Feature</strong></span><span class="sxs-lookup"><span data-stu-id="57bec-111"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="57bec-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1. Generation)</strong></a></span><span class="sxs-lookup"><span data-stu-id="57bec-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="57bec-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="57bec-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="57bec-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive Headsets</strong></a></span><span class="sxs-lookup"><span data-stu-id="57bec-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="57bec-115">Anvingen mit den Augen</span><span class="sxs-lookup"><span data-stu-id="57bec-115">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="57bec-116">✔️</span><span class="sxs-lookup"><span data-stu-id="57bec-116">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="head-and-eye-tracking-design-concepts-demo"></a><span data-ttu-id="57bec-117">Demo zu Designkonzepten für Kopf- und Blickverfolgung</span><span class="sxs-lookup"><span data-stu-id="57bec-117">Head and eye tracking design concepts demo</span></span>

<span data-ttu-id="57bec-118">Wenn Sie Designkonzepte für Kopf- und Blickverfolgung in Aktion sehen möchten, sehen Sie sich die Videodemo **Designing Holograms - Head Tracking and Eye Tracking** (Entwerfen von Hologrammen – Kopfverfolgung und Eyetracking) weiter unten an.</span><span class="sxs-lookup"><span data-stu-id="57bec-118">If you'd like to see Head and Eye Tracking design concepts in action, check out our **Designing Holograms - Head Tracking and Eye Tracking** video demo below.</span></span> <span data-ttu-id="57bec-119">Wenn Sie fertig sind, fahren Sie fort, um ausführlichere Informationen zu bestimmten Themen zu erhalten.</span><span class="sxs-lookup"><span data-stu-id="57bec-119">When you've finished, continue on for a more detailed dive into specific topics.</span></span>

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

<span data-ttu-id="57bec-120">*Dieses Video wurde aus der App "Entwerfen von Hologrammen" HoloLens 2 aufgenommen. Laden Sie hier herunter, und profitieren Sie [von der vollständigen Erfahrung.](https://aka.ms/dhapp)*</span><span class="sxs-lookup"><span data-stu-id="57bec-120">*This video was taken from the "Designing Holograms" HoloLens 2 app. Download and enjoy the full experience [here](https://aka.ms/dhapp).*</span></span>

## <a name="calibration"></a><span data-ttu-id="57bec-121">Kalibrierung</span><span class="sxs-lookup"><span data-stu-id="57bec-121">Calibration</span></span> 

<span data-ttu-id="57bec-122">Damit eye tracking richtig funktioniert, muss jeder Benutzer [](/hololens/hololens-calibration) eine Eyetracking-Benutzer kalibrieren, für die der Benutzer einen Satz holografischer Ziele betrachten muss.</span><span class="sxs-lookup"><span data-stu-id="57bec-122">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](/hololens/hololens-calibration) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="57bec-123">Auf diese Weise kann das Gerät das System für eine komfortablere und qualitativ hochwertigere Anzeige anpassen und gleichzeitig eine genaue Blickverfolgung sicherstellen.</span><span class="sxs-lookup"><span data-stu-id="57bec-123">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="57bec-124">Eyetracking sollte für die meisten Benutzer funktionieren, aber es gibt selten Fälle, in denen ein Benutzer nicht erfolgreich kalibrieren kann.</span><span class="sxs-lookup"><span data-stu-id="57bec-124">Eye tracking should work for most users, but there are rare cases in which a user can't calibrate successfully.</span></span> <span data-ttu-id="57bec-125">Die Kalibrierung kann aus verschiedenen Gründen fehlschlagen, einschließlich, aber nicht beschränkt auf:</span><span class="sxs-lookup"><span data-stu-id="57bec-125">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="57bec-126">Der Benutzer hat sich zuvor vom Kalibrierungsprozess abgemeldet.</span><span class="sxs-lookup"><span data-stu-id="57bec-126">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="57bec-127">Der Benutzer wurde ablenkend und hat die Kalibrierungsziele nicht befolgt.</span><span class="sxs-lookup"><span data-stu-id="57bec-127">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="57bec-128">Der Benutzer verfügt über bestimmte Arten von Kontaktobjektiven und Brillen, die das System noch nicht unterstützt.</span><span class="sxs-lookup"><span data-stu-id="57bec-128">The user has certain types of contact lenses and glasses, which the system doesn't yet support</span></span> 
* <span data-ttu-id="57bec-129">Der Benutzer hat bestimmte Augen- oder Augenbedingungen oder hatte Augenaussichten, die das System noch nicht unterstützt.</span><span class="sxs-lookup"><span data-stu-id="57bec-129">The user has certain eye physiology, eye conditions or had eye surgery, which the system doesn't yet support</span></span>  
* <span data-ttu-id="57bec-130">Externe Faktoren, die eine zuverlässige Blickverfolgung verhindern, z. B. Verblendungen auf dem HoloLens-Visier oder der Brille, intensive direkte Brillen und Verdeckungen durch Diebe vor den Augen</span><span class="sxs-lookup"><span data-stu-id="57bec-130">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="57bec-131">Entwickler sollten sicherstellen, dass sie eine angemessene Unterstützung für Benutzer bereitstellen, für die eye tracking-Daten möglicherweise nicht verfügbar sind (die nicht in der Lage sind, erfolgreich zu kalibrieren).</span><span class="sxs-lookup"><span data-stu-id="57bec-131">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who aren't able to calibrate successfully).</span></span> <span data-ttu-id="57bec-132">Im Abschnitt am unteren Rand dieser Seite haben wir Empfehlungen für Fallbacklösungen bereitgestellt.</span><span class="sxs-lookup"><span data-stu-id="57bec-132">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="57bec-133">Weitere Informationen zur Kalibrierung und zur Sicherstellung eines reibungslosen Ablaufs finden Sie auf unserer Seite zur Kalibrierung von [Eyetrackingbenutzern.](/hololens/hololens-calibration)</span><span class="sxs-lookup"><span data-stu-id="57bec-133">To learn more about the calibration and about how to ensure a smooth experience, check our [eye tracking user calibration](/hololens/hololens-calibration) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="57bec-134">Verfügbare Eyetrackingdaten</span><span class="sxs-lookup"><span data-stu-id="57bec-134">Available eye tracking data</span></span>

<span data-ttu-id="57bec-135">Bevor wir uns mit bestimmten Anwendungsfällen für die Eingabe von Anverfolgen mit den Augen nähern, möchten wir kurz auf die Funktionen hinweisen, die die HoloLens 2 [Eye Tracking-API](/uwp/api/windows.perception.people.eyespose) bietet.</span><span class="sxs-lookup"><span data-stu-id="57bec-135">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="57bec-136">Entwickler erhalten Bei ca. _30 FPS (30 Hz)_ Zugriff auf einen einzelnen Anviert-Strahl mit den Augen (Ursprung und Richtung des Anvierens).</span><span class="sxs-lookup"><span data-stu-id="57bec-136">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="57bec-137">Ausführlichere Informationen zum Zugriff auf Eyetrackingdaten finden Sie in unseren Entwicklerhandbüchern zum Verwenden des [Anvierens mit](../develop/native/gaze-in-directx.md) den Augen in DirectX und [zum Anvieren mit den Augen in Unity.](https://aka.ms/mrtk-eyes)</span><span class="sxs-lookup"><span data-stu-id="57bec-137">For more detailed information about how to access eye tracking data, refer to our developer guides for using [eye-gaze in DirectX](../develop/native/gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="57bec-138">Das vorhergesagte Anvieren mit den Augen liegt ungefähr innerhalb von 1,5 Grad im visuellen Winkel um das tatsächliche Ziel (siehe abbildung unten).</span><span class="sxs-lookup"><span data-stu-id="57bec-138">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="57bec-139">Da geringfügige Ungenauigkeiten erwartet werden, sollten Entwickler einen Gewissensrand um diesen unteren Grenzwert planen (z.B. können 2,0 bis 3,0 Grad zu einer viel komfortableren Erfahrung führen).</span><span class="sxs-lookup"><span data-stu-id="57bec-139">As slight imprecisions are expected, developers should plan for some margin around this lower-bound value (for example, 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="57bec-140">Im Folgenden erfahren Sie, wie Sie die Auswahl kleiner Ziele genauer behandeln.</span><span class="sxs-lookup"><span data-stu-id="57bec-140">We'll discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="57bec-141">Damit die Blickverfolgung exakt funktioniert, muss jeder Benutzer eine Benutzerkalibrierung für seine Blickverfolgung durchlaufen.</span><span class="sxs-lookup"><span data-stu-id="57bec-141">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="57bec-142">![Optimale Zielgröße im Abstand von 2 Metern](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="57bec-142">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="57bec-143">*Optimale Zielgröße in einer Entfernung von 2 Metern*</span><span class="sxs-lookup"><span data-stu-id="57bec-143">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="57bec-144">Anwendungsfälle</span><span class="sxs-lookup"><span data-stu-id="57bec-144">Use cases</span></span>

<span data-ttu-id="57bec-145">Mit der Blickverfolgung können Anwendungen in Echtzeit verfolgen, wohin der Benutzer schaut.</span><span class="sxs-lookup"><span data-stu-id="57bec-145">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="57bec-146">In den folgenden Anwendungsfällen werden einige Interaktionen beschrieben, die mit eye tracking auf HoloLens 2 in Mixed Reality möglich sind.</span><span class="sxs-lookup"><span data-stu-id="57bec-146">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="57bec-147">Diese Anwendungsfälle sind noch nicht Teil der Holographic Shell-Benutzeroberfläche (d. h. der Schnittstelle, die Sie beim Starten Ihrer Anwendung HoloLens 2).</span><span class="sxs-lookup"><span data-stu-id="57bec-147">These use cases aren't yet part of the Holographic Shell experience (that is, the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="57bec-148">Sie können einige davon im [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)ausprobieren, das mehrere interessante und leistungsstarke Beispiele für die Verwendung von Eyetracking bietet, z. B. schnelle und mühelose, durch die Augen unterstützte Zielauswahl und automatisches Scrollen durch Text basierend auf dem, was der Benutzer betrachtet.</span><span class="sxs-lookup"><span data-stu-id="57bec-148">You can try some of them in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html), which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections, and automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="57bec-149">Benutzerabsicht</span><span class="sxs-lookup"><span data-stu-id="57bec-149">User intent</span></span>

<span data-ttu-id="57bec-150">Informationen darüber, wo und was ein Benutzer betrachtet, bieten einen leistungsstarken Kontext für andere Eingaben, z. B. Stimme, Hände und Controller.</span><span class="sxs-lookup"><span data-stu-id="57bec-150">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands, and controllers.</span></span>
<span data-ttu-id="57bec-151">Dies kann für verschiedene Aufgaben verwendet werden.</span><span class="sxs-lookup"><span data-stu-id="57bec-151">This can be used for various tasks.</span></span>
<span data-ttu-id="57bec-152">Dies kann z. B.  von der schnellen und mühelosen Ausrichtung auf die gesamte Szene reichen, indem ein Hologramm betrachtet wird und *"Auswählen"* (siehe auch Anvieren und [Commit)](gaze-and-commit.md)oder *"Put this..."* gesagt wird, dann der Blick auf den Ort, an dem der Benutzer das Hologramm platzieren möchte, und *"... there" auf.*</span><span class="sxs-lookup"><span data-stu-id="57bec-152">For example, this can range from quickly and effortlessly **targeting** across the scene by looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="57bec-153">Beispiele hierfür finden Sie in den Artikeln [Mixed Reality Toolkit – Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) (Mixed Reality-Toolkit – Blickgestützte Zielauswahl) und [Mixed Reality Toolkit – Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html) (Mixed Reality-Toolkit – Blickgestützte Zielpositionierung).</span><span class="sxs-lookup"><span data-stu-id="57bec-153">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="57bec-154">Darüber hinaus kann ein Beispiel für die Benutzerabsicht die Verwendung von Informationen darüber enthalten, was Benutzer betrachten, um die Interaktion mit verfachten virtuellen Agents und interaktiven Hologrammen zu verbessern.</span><span class="sxs-lookup"><span data-stu-id="57bec-154">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="57bec-155">Beispielsweise können virtuelle Agents verfügbare Optionen und ihr Verhalten basierend auf aktuell angezeigten Inhalten anpassen.</span><span class="sxs-lookup"><span data-stu-id="57bec-155">For instance, virtual agents might adapt available options and their behavior, based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="57bec-156">Implizite Aktionen</span><span class="sxs-lookup"><span data-stu-id="57bec-156">Implicit actions</span></span>

<span data-ttu-id="57bec-157">Die Kategorie der impliziten Aktionen steht in enger Beziehung zur Benutzerabsicht.</span><span class="sxs-lookup"><span data-stu-id="57bec-157">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="57bec-158">Die Idee ist, dass Hologramme oder Benutzeroberflächenelemente auf instinktive Weise reagieren, die sich möglicherweise nicht einmal so anfühlt, als ob der Benutzer mit dem System interagiert, sondern dass das System und der Benutzer synchron sind. Ein Beispiel  hierfür ist die automatische Bildlauf-Funktion, bei der der Benutzer einen langen Text lesen kann, der automatisch beginnt, zu scrollen, sobald der Benutzer zum Ende des Textfelds kommt, um den Benutzer im Lesefluss zu halten, ohne einen Finger zu heben.</span><span class="sxs-lookup"><span data-stu-id="57bec-158">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text, which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading, without lifting a finger.</span></span>  
<span data-ttu-id="57bec-159">Ein wichtiger Aspekt dabei ist, dass sich die Bildlaufgeschwindigkeit an die Lesegeschwindigkeit des Benutzers anpasst.</span><span class="sxs-lookup"><span data-stu-id="57bec-159">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="57bec-160">Ein weiteres Beispiel ist **der mit** den Augen unterstützte Zoom und Schwenken, bei dem der Benutzer genau das sehen kann, worauf er sich konzentriert.</span><span class="sxs-lookup"><span data-stu-id="57bec-160">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she's focused on.</span></span> <span data-ttu-id="57bec-161">Das Auslösen und Steuern der Zoomgeschwindigkeit kann durch Spracheingaben oder Handeingaben gesteuert werden. Dies ist wichtig, um dem Benutzer das Gefühl der Kontrolle zu geben und gleichzeitig eine Überlastung zu vermeiden.</span><span class="sxs-lookup"><span data-stu-id="57bec-161">Triggering and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="57bec-162">Im Folgenden werden diese Entwurfsüberlegungen ausführlicher erläutert.</span><span class="sxs-lookup"><span data-stu-id="57bec-162">We'll talk about these design considerations in more detail below.</span></span> <span data-ttu-id="57bec-163">Nach dem Vergrößern kann der Benutzer problemlos dem Lauf einer Straße folgen, um seine Umgebung mithilfe des Anvierens mit den Augen zu erkunden.</span><span class="sxs-lookup"><span data-stu-id="57bec-163">Once zoomed in, the user can smoothly follow, for example, the course of a street to explore his or her neighborhood by using their eye-gaze.</span></span>
<span data-ttu-id="57bec-164">Demobeispiele für diese Arten von Interaktion finden Sie im Beispiel [Mixed Reality Toolkit – Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) (Mixed Reality-Toolkit – Blickgestützte Navigation).</span><span class="sxs-lookup"><span data-stu-id="57bec-164">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="57bec-165">Andere Anwendungsfälle für _implizite Aktionen_ können Folgendes umfassen:</span><span class="sxs-lookup"><span data-stu-id="57bec-165">Other use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="57bec-166">**Intelligente Benachrichtigungen:** Haben Sie sich jemals darüber geärgert, dass Benachrichtigungen genau dort angezeigt werden, wo Sie suchen?</span><span class="sxs-lookup"><span data-stu-id="57bec-166">**Smart notifications:** Ever get annoyed by notifications popping up right where you're looking?</span></span> <span data-ttu-id="57bec-167">Unter Berücksichtigung der Aufmerksamkeit, auf die ein Benutzer achten muss, können Sie diese Erfahrung verbessern, indem Sie Benachrichtigungen von dem Ort abstellen, an dem der Benutzer gerade arbeitet.</span><span class="sxs-lookup"><span data-stu-id="57bec-167">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="57bec-168">Dies schränkt Ablenkungen ein und schließt sie automatisch, sobald der Benutzer das Lesen abgeschlossen hat.</span><span class="sxs-lookup"><span data-stu-id="57bec-168">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="57bec-169">**Hologramme:** Hologramme, die beim Anvieren unaufdinglich reagieren.</span><span class="sxs-lookup"><span data-stu-id="57bec-169">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="57bec-170">Dies kann von leicht leuchtenden UI-Elementen, einer langsamen Blume bis hin zu einem virtuellen Hund reichen, der mit dem Blick auf den Benutzer beginnt und sein Ende wackelt.</span><span class="sxs-lookup"><span data-stu-id="57bec-170">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="57bec-171">Diese Interaktion kann ein interessantes Gefühl für Konnektivität und Zufriedenheit in Ihrer Anwendung bieten.</span><span class="sxs-lookup"><span data-stu-id="57bec-171">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="57bec-172">Aufmerksamkeitsverfolgung</span><span class="sxs-lookup"><span data-stu-id="57bec-172">Attention tracking</span></span>

<span data-ttu-id="57bec-173">Informationen dazu, wo oder was Benutzer betrachten, können ein äußerst leistungsfähiges Tool sein.</span><span class="sxs-lookup"><span data-stu-id="57bec-173">Information on where or what users look at can be an immensely powerful tool.</span></span> <span data-ttu-id="57bec-174">Sie kann dabei helfen, die Nutzbarkeit von Entwürfen zu bewerten und Probleme in Workflows zu identifizieren, um sie effizienter zu gestalten.</span><span class="sxs-lookup"><span data-stu-id="57bec-174">It can help assess usability of designs and identify problems in workflows to make them more efficient.</span></span>
<span data-ttu-id="57bec-175">Eyetrackingvisualisierung und -analyse sind eine gängige Praxis in verschiedenen Anwendungsbereiche.</span><span class="sxs-lookup"><span data-stu-id="57bec-175">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="57bec-176">Mit HoloLens 2 bieten wir diesem Verständnis eine neue Dimension, da 3D-Hologramme in realen Kontexten platziert und entsprechend bewertet werden können.</span><span class="sxs-lookup"><span data-stu-id="57bec-176">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="57bec-177">Das [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) enthält grundlegende Beispiele für das Protokollieren und Laden von Eyetrackingdaten und deren Visualisierung.</span><span class="sxs-lookup"><span data-stu-id="57bec-177">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>
<span data-ttu-id="57bec-178">Microsoft ist bestrebt, Innovationen zu fördern und gleichzeitig sicherzustellen, dass Benutzer über eine informierte und transparente Erfahrung mit der Verwendung ihrer Eyetrackinginformationen verfügen.</span><span class="sxs-lookup"><span data-stu-id="57bec-178">Microsoft is dedicated to facilitating innovation while ensuring that users have an informed and transparent experience with how their eye tracking information is used.</span></span>  <span data-ttu-id="57bec-179">Wir arbeiten mit unseren Entwicklern und UX-Teams zusammen, um Drittanbieter zu unterstützen, um sicherzustellen, dass die Benutzeroberflächen im Mittelpunkt stehen.</span><span class="sxs-lookup"><span data-stu-id="57bec-179">We'll work with our developers and UX teams to provide guidance for third parties to ensure that experiences are centered around the user.</span></span>  

<span data-ttu-id="57bec-180">Zu diesem Bereich zählen möglicherweise auch die folgenden Anwendungen:</span><span class="sxs-lookup"><span data-stu-id="57bec-180">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="57bec-181">**Visualisierung mit remotem Anvisieren mit den Augen:** Visualisierungen mit remotem Anvisieren mit den Augen: Visualisieren Sie, was Remotemitarbeiter betrachten, um sofortiges Feedback zu geben und eine genauere Verarbeitung von Informationen zu ermöglichen.</span><span class="sxs-lookup"><span data-stu-id="57bec-181">**Remote eye-gaze visualization:** Remote eye-gaze visualizations: Visualize what remote collaborators are looking at, to be able to provide immediate feedback and facilitate more accurate information processing.</span></span>
-   <span data-ttu-id="57bec-182">**Studien zur Benutzerforschung:** Die Aufmerksamkeitsnachverfolgung kann Forscher dabei unterstützen, mehr Erkenntnisse darüber zu gewinnen, wie Benutzer die natürliche Umgebung ohne Beeinträchtigungen erkennen und damit interagieren, um mehr instinktive Interaktionen zwischen Menschen und Computern zu entwerfen.</span><span class="sxs-lookup"><span data-stu-id="57bec-182">**User research studies:** Attention tracking can help researchers get more insights into how users perceive and engage with the natural environment, without interfering, to design more instinctual human-computer-interactions.</span></span> <span data-ttu-id="57bec-183">Eyetracking kann Informationen liefern, die von den Teilnehmern der Studie nicht direkt formuliert werden, die andernfalls von der Forscherin leicht übersehen werden könnten.</span><span class="sxs-lookup"><span data-stu-id="57bec-183">Eye tracking can provide information that is not directly articulated by participants in the study, which otherwise might be easily missed by the researcher.</span></span> 
-   <span data-ttu-id="57bec-184">**Trainings- und Leistungsüberwachung:** Üben und optimieren Sie die Ausführung von Aufgaben, indem Sie Engpässe im Ausführungsfluss effektiver identifizieren.</span><span class="sxs-lookup"><span data-stu-id="57bec-184">**Training and performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span> <span data-ttu-id="57bec-185">Eyetracking kann natürliche, Echtzeit- und zielorientierte Informationen bereitstellen, um Training, Produktivität und Sicherheit am Arbeitsplatz zu verbessern.</span><span class="sxs-lookup"><span data-stu-id="57bec-185">Eye tracking can provide natural, real-time, and objective information to help improve training, productivity, and safety in the workplace.</span></span> 
-   <span data-ttu-id="57bec-186">**Entwurfsauswertungen, Marketing und Verbraucherforschung:** Eyetracking ermöglicht es kommerziellen Unternehmen, Marketing- und Verbraucherstudien in realen Umgebungen durchzuführen oder zu analysieren, was die Aufmerksamkeit eines Benutzers zur Verbesserung des Produkt- oder Raumdesigns erfasst.</span><span class="sxs-lookup"><span data-stu-id="57bec-186">**Design evaluations, marketing, and consumer research:** Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures a user’s attention to improve product or space design.</span></span> 

### <a name="other-use-cases"></a><span data-ttu-id="57bec-187">Weitere Anwendungsfälle</span><span class="sxs-lookup"><span data-stu-id="57bec-187">Other use cases</span></span>

- <span data-ttu-id="57bec-188">**Gaming:** Wollten Sie schon immer superpowers haben?</span><span class="sxs-lookup"><span data-stu-id="57bec-188">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="57bec-189">Hier kommt Ihre Chance!</span><span class="sxs-lookup"><span data-stu-id="57bec-189">Here's your chance!</span></span> <span data-ttu-id="57bec-190">Sie können Hologramme verstechen, indem Sie sie an ihnen ansteuern.</span><span class="sxs-lookup"><span data-stu-id="57bec-190">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="57bec-191">Schneidelasen von deinen Augen – probieren Sie es in [RoboRaid aus, um HoloLens 2.](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)</span><span class="sxs-lookup"><span data-stu-id="57bec-191">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="57bec-192">Machen Sie die Enanständung in Steine, oder fixieren Sie sie.</span><span class="sxs-lookup"><span data-stu-id="57bec-192">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="57bec-193">Verwenden Sie Ihren Röntgenblick, um Gebäude zu erkunden.</span><span class="sxs-lookup"><span data-stu-id="57bec-193">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="57bec-194">Ihrer Phantasie sind keine Grenzen gesetzt!</span><span class="sxs-lookup"><span data-stu-id="57bec-194">Your imagination is the limit!</span></span>
<span data-ttu-id="57bec-195">Sie sollten den Benutzer jedoch nicht überfordern. Um mehr zu erfahren, sehen Sie sich unsere Richtlinien für den Entwurf von Eingaben mit Blick [an.](eye-gaze-interaction.md)</span><span class="sxs-lookup"><span data-stu-id="57bec-195">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="57bec-196">**Ausdrucksstärkere Avatare:** Eyetracking unterstützt ausdrucksstärkere 3D-Avatare, indem live Eye Tracking-Daten verwendet werden, um die Augen des Avatars zu animieren, die angeben, was der Benutzer anschaut.</span><span class="sxs-lookup"><span data-stu-id="57bec-196">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="57bec-197">**Texteintrag:** Eyetracking kann als Alternative für die Eingabe von Text mit geringem Aufwand verwendet werden, insbesondere dann, wenn Sprache oder Hände nicht verwendet werden können.</span><span class="sxs-lookup"><span data-stu-id="57bec-197">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="57bec-198">Verwenden des Anvings mit den Augen für die Interaktion</span><span class="sxs-lookup"><span data-stu-id="57bec-198">Using eye-gaze for interaction</span></span>

<span data-ttu-id="57bec-199">Es kann schwierig sein, eine Interaktion zu erstellen, die die Schnellsteuerung mit den Augen nutzt.</span><span class="sxs-lookup"><span data-stu-id="57bec-199">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="57bec-200">Auf der einen Seite bewegen sich die Augen so schnell, dass Sie darauf achten müssen, wie Sie die Eingabe zum Anvieren mit den Augen verwenden, da benutzer andernfalls die Erfahrung überwältigend oder ablenkend finden.</span><span class="sxs-lookup"><span data-stu-id="57bec-200">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="57bec-201">Auf der anderen Seite können Sie auch wirklich magische Erfahrungen erstellen, die Ihre Benutzer anregen!</span><span class="sxs-lookup"><span data-stu-id="57bec-201">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="57bec-202">Um Ihnen zu helfen, sehen Sie sich unsere Übersicht über wichtige Vorteile, Herausforderungen und Entwurfsempfehlungen für die Interaktion mit [den Augen an.](eye-gaze-interaction.md)</span><span class="sxs-lookup"><span data-stu-id="57bec-202">To help you, check out our overview of key advantages, challenges, and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 
 
## <a name="fallback-solutions-when-eye-tracking-isnt-available"></a><span data-ttu-id="57bec-203">Fallbacklösungen, wenn eye tracking nicht verfügbar ist</span><span class="sxs-lookup"><span data-stu-id="57bec-203">Fallback solutions when eye tracking isn't available</span></span>

<span data-ttu-id="57bec-204">In seltenen Fällen sind Eyetrackingdaten möglicherweise nicht verfügbar.</span><span class="sxs-lookup"><span data-stu-id="57bec-204">In rare cases, eye tracking data might not be available.</span></span>
<span data-ttu-id="57bec-205">Dies kann verschiedene Gründe haben, aus denen die gängigsten unten aufgeführt sind:</span><span class="sxs-lookup"><span data-stu-id="57bec-205">This can be because of different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="57bec-206">Das System konnte den Benutzer nicht [kalibrieren.](/hololens/hololens-calibration)</span><span class="sxs-lookup"><span data-stu-id="57bec-206">The system failed to [calibrate the user](/hololens/hololens-calibration).</span></span>
* <span data-ttu-id="57bec-207">Der Benutzer hat die [Kalibrierung übersprungen.](/hololens/hololens-calibration)</span><span class="sxs-lookup"><span data-stu-id="57bec-207">The user skipped the [calibration](/hololens/hololens-calibration).</span></span>   
* <span data-ttu-id="57bec-208">Der Benutzer ist kalibriert, hat sich aber entschieden, Ihrer App keine Berechtigung zur Verwendung seiner Eyetrackingdaten zu erteilen.</span><span class="sxs-lookup"><span data-stu-id="57bec-208">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="57bec-209">Der Benutzer verfügt über eine eindeutige Brille oder eine Augenbedingung, die das System noch nicht unterstützt.</span><span class="sxs-lookup"><span data-stu-id="57bec-209">The user has unique eyeglasses or some eye condition that the system doesn't yet support.</span></span> 
* <span data-ttu-id="57bec-210">Externe Faktoren, die eine zuverlässige Blickverfolgung verhindern, z. B. Verblendungen des HoloLens-Visiers oder der Brille, intensive direkte Brillen und Verdeckungen aufgrund von Härchen vor den Augen.</span><span class="sxs-lookup"><span data-stu-id="57bec-210">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions because of hair in front of the eyes.</span></span>

<span data-ttu-id="57bec-211">Entwickler sollten sicherstellen, dass für diese Benutzer geeignete Fallbackunterstützung vorhanden ist.</span><span class="sxs-lookup"><span data-stu-id="57bec-211">Developers should ensure that there's appropriate fallback support for these users.</span></span> <span data-ttu-id="57bec-212">Auf der Seite [Eye Tracking in DirectX (Blickverfolgung in DirectX)](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) werden die APIs erläutert, die erforderlich sind, um zu erkennen, ob Eyetrackingdaten verfügbar sind.</span><span class="sxs-lookup"><span data-stu-id="57bec-212">On the [Eye Tracking in DirectX](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="57bec-213">Einige Benutzer haben sich möglicherweise bewusst dafür entschieden, den Zugriff auf ihre Eyetrackingdaten aufzuheben, und sind mit dem Kompromiss einer vertrauenswürdigen Benutzererfahrung mit dem Datenschutz in Ordnung, dass sie keinen Zugriff auf ihre Eyetrackingdaten bieten, in einigen Fällen kann dies unbeabsichtigt sein.</span><span class="sxs-lookup"><span data-stu-id="57bec-213">While some users may have consciously decided to revoke,  access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="57bec-214">Wenn Ihre App eye tracking verwendet und dies ein wichtiger Teil der Benutzeroberfläche ist, empfehlen wir, dies dem Benutzer klar mitzuteilen.</span><span class="sxs-lookup"><span data-stu-id="57bec-214">If your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>   

<span data-ttu-id="57bec-215">Wenn Sie dem Benutzer mitteilen, warum eye tracking für Ihre Anwendung wichtig ist (möglicherweise sogar einige erweiterte Features auflisten), um das volle Potenzial Ihrer Anwendung zu erleben, kann der Benutzer besser verstehen, was er aufgibt.</span><span class="sxs-lookup"><span data-stu-id="57bec-215">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application, can help the user to better understand what they're giving up.</span></span> <span data-ttu-id="57bec-216">Helfen Sie dem Benutzer, zu ermitteln, warum eye tracking möglicherweise nicht funktioniert (basierend auf den obigen Überprüfungen), und bieten Sie einige Vorschläge, um potenzielle Probleme schnell zu beheben.</span><span class="sxs-lookup"><span data-stu-id="57bec-216">Help the user identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> 

<span data-ttu-id="57bec-217">Wenn Sie z. B. erkennen können, dass das System Eyetracking unterstützt, der Benutzer kalibriert wird und sogar seine Berechtigung erteilt hat, aber keine Eyetrackingdaten empfangen werden, kann dies auf einige andere Probleme verweisen, z. B. Auftäusche oder augenverblendete Augen.</span><span class="sxs-lookup"><span data-stu-id="57bec-217">For example, if you can detect that the system supports eye tracking, the user is calibrated and has even given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> 

<span data-ttu-id="57bec-218">Es gibt seltene Fälle von Benutzern, für die eye tracking möglicherweise nicht funktioniert.</span><span class="sxs-lookup"><span data-stu-id="57bec-218">There are rare cases of users for whom eye tracking may not work.</span></span> <span data-ttu-id="57bec-219">Denken Sie daran, indem Sie zulassen, erinnerungen zu ver- oder sogar zu deaktivieren, um eye tracking in Ihrer App zu aktivieren.</span><span class="sxs-lookup"><span data-stu-id="57bec-219">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fall-back-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="57bec-220">Fall back for apps using eye-gaze as a primary input pointer (Fall back für Apps, die das Anvingen mit den Augen als primären Eingabezeiger verwenden)</span><span class="sxs-lookup"><span data-stu-id="57bec-220">Fall back for apps using eye-gaze as a primary input pointer</span></span>

<span data-ttu-id="57bec-221">Wenn Ihre App das Anvieren mit den Augen als Zeigereingabe verwendet, um hologramme in der gesamten Szene schnell auszuwählen, die Eyetrackingdaten jedoch nicht verfügbar sind, empfehlen wir, zurück zum Anvieren mit dem Kopf zu fallen und mit dem Zeigen des Cursors mit dem Kopf zu beginnen.</span><span class="sxs-lookup"><span data-stu-id="57bec-221">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="57bec-222">Es wird empfohlen, ein Timeout (z. B. 500–1500 ms) zu verwenden, um zu bestimmen, ob sie wechseln möchten.</span><span class="sxs-lookup"><span data-stu-id="57bec-222">We recommend using a timeout (for example, 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="57bec-223">Diese Aktion verhindert, dass Cursor jedes Mal angezeigt werden, wenn das System aufgrund schneller Augenbewegungen oder Winks und Blinken kurzzeitig die Nachverfolgung verliert.</span><span class="sxs-lookup"><span data-stu-id="57bec-223">This action prevents cursors from appearing every time the system may briefly lose tracking because of fast eye motions or winks and blinks.</span></span> <span data-ttu-id="57bec-224">Wenn Sie Ein Unity-Entwickler sind, wird das automatische Fallback zum Anvischen mit dem Kopf bereits im Mixed Reality Behandelt.</span><span class="sxs-lookup"><span data-stu-id="57bec-224">If you're a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="57bec-225">Wenn Sie DirectX-Entwickler sind, müssen Sie diesen Schalter selbst behandeln.</span><span class="sxs-lookup"><span data-stu-id="57bec-225">If you're a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fall-back-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="57bec-226">Fall back for other eye-tracking-specific applications (Fall back für andere Eye-Tracking-spezifische Anwendungen)</span><span class="sxs-lookup"><span data-stu-id="57bec-226">Fall back for other eye-tracking-specific applications</span></span>

<span data-ttu-id="57bec-227">Ihre App kann das Anvingen mit den Augen auf einzigartige Weise verwenden, die speziell auf die Augen zugeschnitten ist.</span><span class="sxs-lookup"><span data-stu-id="57bec-227">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes.</span></span> <span data-ttu-id="57bec-228">Beispielsweise das Animieren der Augen eines Avatars oder für wärmebildbasierte Blicke, die auf genauen Informationen zur visuellen Aufmerksamkeit basieren.</span><span class="sxs-lookup"><span data-stu-id="57bec-228">For example, animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="57bec-229">In diesem Fall gibt es keinen eindeutigen Fallback.</span><span class="sxs-lookup"><span data-stu-id="57bec-229">In this case, there's no clear fallback.</span></span> <span data-ttu-id="57bec-230">Wenn eye tracking nicht verfügbar ist, müssen diese Funktionen möglicherweise deaktiviert werden.</span><span class="sxs-lookup"><span data-stu-id="57bec-230">If eye tracking isn't available, these capabilities may need to be disabled.</span></span>
<span data-ttu-id="57bec-231">Auch hier wird empfohlen, dies dem Benutzer klar zu vermitteln, der möglicherweise nicht weiß, dass die Funktion nicht funktioniert.</span><span class="sxs-lookup"><span data-stu-id="57bec-231">Again, we recommend to clearly communicate this to the user who may be unaware that the capability isn't working.</span></span>

<br>

<span data-ttu-id="57bec-232">Auf dieser Seite haben Sie hoffentlich einen guten Überblick erhalten, damit Sie sich mit der Rolle der Eyetracking- und Eye-Gaze-Eingabe für HoloLens 2.</span><span class="sxs-lookup"><span data-stu-id="57bec-232">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="57bec-233">Um mit der Entwicklung zu beginnen, sehen Sie sich unsere Informationen zur Rolle des Anvierens mit den Augen für die [Interaktion mit Hologrammen,](eye-gaze-interaction.md)das [Anvieren mit](https://aka.ms/mrtk-eyes) den Augen in Unity und das [Anvieren mit den Augen in DirectX](../develop/native/gaze-in-directx.md)an.</span><span class="sxs-lookup"><span data-stu-id="57bec-233">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](../develop/native/gaze-in-directx.md).</span></span>

## <a name="see-also"></a><span data-ttu-id="57bec-234">Weitere Informationen</span><span class="sxs-lookup"><span data-stu-id="57bec-234">See also</span></span>

* [<span data-ttu-id="57bec-235">Kalibrierung</span><span class="sxs-lookup"><span data-stu-id="57bec-235">Calibration</span></span>](/hololens/hololens-calibration)
* [<span data-ttu-id="57bec-236">Komfort</span><span class="sxs-lookup"><span data-stu-id="57bec-236">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="57bec-237">Interaktion durch Anvisieren</span><span class="sxs-lookup"><span data-stu-id="57bec-237">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="57bec-238">Anvischen mit den Augen in DirectX</span><span class="sxs-lookup"><span data-stu-id="57bec-238">Eye-gaze in DirectX</span></span>](../develop/native/gaze-in-directx.md)
* [<span data-ttu-id="57bec-239">Anvieren mit den Augen in Unity (Mixed Reality Toolkit)</span><span class="sxs-lookup"><span data-stu-id="57bec-239">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="57bec-240">Anvisieren und Ausführen</span><span class="sxs-lookup"><span data-stu-id="57bec-240">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="57bec-241">Spracheingabe</span><span class="sxs-lookup"><span data-stu-id="57bec-241">Voice input</span></span>](../out-of-scope/voice-design.md)
