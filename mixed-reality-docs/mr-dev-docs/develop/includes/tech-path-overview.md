---
ms.openlocfilehash: ab95f0c89a4b77c6ea69fefa331bfbdccf35f79d
ms.sourcegitcommit: 3e36b2fbbcc250c49aaf8ca1b6133cf0e9db69fa
ms.translationtype: HT
ms.contentlocale: de-DE
ms.lasthandoff: 04/16/2021
ms.locfileid: "107564608"
---
# <a name="unity"></a>[Unity](#tab/unity)

![Unity](../images/unity_logo_banner.png)<br>

Erstellen Sie eine plattformübergreifende, umfassende Mixed Reality-App mit Unity. Lesen Sie die [Unity-Entwicklung – Übersicht](../unity/unity-development-overview.md), um in die Unity-Entwicklung für HoloLens oder immersive Headsets für Windows Mixed Reality einzusteigen.

## <a name="available-hardware-platforms"></a>Verfügbare Hardwareplattformen

Bei der Erstellung von Mixed Reality-Apps mit Unity stehen Ihnen mehrere Hardware- und Emulatoroptionen zur Verfügung. Während sich unsere Entwicklerdokumentation auf HoloLens-Geräte konzentriert, finden Sie Abschnitte zur Geräteunterstützung mit Details zur Bereitstellung von immersiven Headsets, falls zutreffend.

**Augmented Reality-Geräte**
* [HoloLens (1. Generation)](/hololens/hololens1-hardware)
* [HoloLens 2](/hololens/hololens2-hardware)

**Immersive Headsets (VR)**
* HP Reverb und Reverb G2
* Samsung Odyssey und Odyssey+
* HP Windows Mixed Reality-Headset
* Lenovo-Explorer
* Acer AH101
* Dell Visor
* Asus HC102
* Acer OJO 500

## <a name="available-tools-and-sdks"></a>Verfügbare Tools und SDKs

|  Tool/SDK  |  Beschreibung  |
| --- | --- |
| [Mixed Reality-Toolkit für Unity](../unity/mrtk-getting-started.md) | Das Mixed Reality-Toolkit für Unity ist ein plattformübergreifendes Open-Source-Entwicklungskit, das entwickelt wurde, um die Entwicklung von Anwendungen für Microsoft HoloLens, immersive Windows Mixed Reality-Headsets (VR) und die OpenVR-Plattform zu beschleunigen. |
| [Microsoft World Locking-Tools](https://microsoft.github.io/MixedReality-WorldLockingTools-Unity/DocGen/Documentation/GettingStartedWithWorldLocking.html) | Stellt ein stabiles Koordinatensystem und eine Kameraanpassung zur Verfügung, mit denen die sichtbaren Inkonsistenzen minimiert werden. |
| [Microsoft Mesh](/mesh/overview) – private Vorschau | Füllen Sie das Formular zum [Interesse an der Registrierung für Microsoft Mesh](https://aka.ms/meshsignup) aus, um auf dem neuesten Stand der Ankündigungen und Neuigkeiten zu Mesh zu bleiben. Mit Mesh können Sie virtuelle Besprechungen verbessern, virtuelle Entwurfssitzungen abhalten, andere Personen remote unterstützen und virtuelle Besprechungen hosten. |

## <a name="cloud-services"></a>Clouddienste

Es gibt mehrere Clouddienste, die in Mixed Reality-Projekte integriert werden können, die in Unity erstellt werden, insbesondere **Azure Remote Rendering** und **Azure Spatial Anchors**. Diese Dienste können Ihren Anwendungen freigegebene holografische Inhalte und 3D-Echtzeitrendering hinzufügen, wodurch sie für Ihre Benutzer fesselnder und immersiver werden.

Alle diese Dienste werden im Rahmen der [Unity-Entwicklungsjourney für HoloLens](../unity/unity-development-overview.md) behandelt, die den **dringend empfohlenen Pfad für das Erlernen von Mixed Reality mit Unity** darstellt. Sie befinden sich bereits auf diesem Weg, lesen Sie also einfach weiter, und folgen Sie der großen blauen Schaltfläche am Ende des Artikels. Wenn Sie sich jedoch in einem weiter fortgeschrittenen Lernstadium befinden und bereits wissen, dass Sie fortfahren möchten, sehen Sie sich unsere [Übersicht über Cloud Services](../mixed-reality-cloud-services.md) an, oder wechseln Sie direkt zu den [Dienstressourcen](../unity/unity-development-overview.md#5-adding-services).

## <a name="dynamics-365-guides"></a>Dynamics 365-Leitfäden

Sie können **Microsoft Dynamics 365-Leitfäden** verwenden, um holografische Anweisungen visuell mit der virtuellen Umgebung Ihrer Apps zu verknüpfen und Ihren Benutzern wichtige Informationen zu geben, wann und wo sie gebraucht werden. Diese Funktion wird auch in der Unity-Entwicklungsjourney für HoloLens behandelt, aber wenn Sie einen Blick nach vorn riskieren möchten, können Sie [hier](../unity/unity-development-overview.md#5-adding-services) die **Dynamics 365-Registerkarte** auswählen und sich ansehen, was zur Wahl steht.

## <a name="examples"></a>Beispiele

Wir haben mehrere Open-Source-[Beispiel-Apps](../features-and-samples.md), die Sie herunterladen können, um damit zu experimentieren und ein Gefühl für ein Mixed Reality-Endprodukt in Unity zu bekommen. Es stehen auch MRTK-Beispielszenen bereit, mit denen Sie bestimmte Features testen können:

* [Szene mit Beispielen für Handinteraktion (MRTK) für Unity](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/hand-interaction-examples): Die Beispielszene „HandInteractionExamples.unity“ enthält verschiedene Typen von Interaktionen und Steuerelementen der Benutzeroberfläche, die artikulierte Handeingaben hervorheben.

* [Beispiele für Eyetracking (MRTK) für Unity](https://docs.microsoft.com/windows/mixed-reality/mrtk-unity/features/example-scenes/eye-tracking-examples-overview): Auf dieser Seite erfahren Sie, wie Sie schnell mit der Verwendung der Blickverfolgung (Eyetracking) in MRTK beginnen können, indem Sie auf unseren bereitgestellten MRTK-Beispielen für die Blickverfolgung aufbauen.

>[!NOTE]
>Beide MRTK-Beispielszenen erfordern die Installation der Pakete MRTK Foundation und Example Unity.

# <a name="unreal"></a>[Unreal](#tab/unreal)

![Unreal](../images/unreal_logo_banner.png)

Erstellen Sie eine plattformübergreifende, umfassende Mixed Reality-App mit Unreal. Informationen zum Einstieg in die Unreal-Entwicklung für HoloLens finden Sie in der [Unreal-Entwicklung – Übersicht](../unreal/unreal-development-overview.md).

## <a name="available-hardware-platforms"></a>Verfügbare Hardwareplattformen

Bei der Erstellung von Mixed Reality-Apps mit der Unreal-Engine stehen Ihnen mehrere Hardware-, Emulator- und Streamingoptionen zur Verfügung. Unsere Entwicklerdokumentation konzentriert sich zwar auf HoloLens-Geräte, aber Sie können Ihre Unreal-Projekte als x64-Desktop-Apps verpacken und sie genauso gut auf immersiven Headsets ausführen.

**Augmented Reality-Geräte**
* [HoloLens (1. Generation)](/hololens/hololens1-hardware)
* [HoloLens 2](/hololens/hololens2-hardware)

**Immersive Headsets (VR)**
* HP Reverb und Reverb G2
* Samsung Odyssey und Odyssey+
* HP Windows Mixed Reality-Headset
* Lenovo-Explorer
* Acer AH101
* Dell Visor
* Asus HC102
* Acer OJO 500

## <a name="available-tools-and-sdks"></a>Verfügbare Tools und SDKs

|  Tool/SDK  |  Beschreibung  |
| --- | --- |
| [UX-Tools für Unreal](https://github.com/microsoft/MixedRealityToolkit-Unreal) | UX Tools ist das erste Plug-In, das veröffentlicht wird. Derzeit wird es nur auf HoloLens 2 unterstützt. Das Plug-In enthält C++-Code, Blaupausen und Beispielressourcen für gängige UX-Funktionen für Eingabesimulationen, Handinteraktionen, Oberflächenmagnetismus und vieles mehr. |
| [Grafiktools für Unreal](https://github.com/microsoft/MixedReality-GraphicsTools-Unreal/) | Grafiktools ist ein UE-Spiele-Plug-In mit Code, Blaupausen und Beispielobjekten, die erstellt wurden, um die visuelle Genauigkeit von Mixed Reality-Anwendungen zu verbessern und gleichzeitig Leistungsbudgets einzuhalten. |

## <a name="cloud-services"></a>Clouddienste

Beim Erstellen von Mixed Reality-Apps in Unreal haben Sie Zugriff auf einen leistungsfähigen Clouddienst mit dem Namen **Azure Spatial Anchors**, den Sie verwenden können, um holografische Inhalte übergreifend über verschiedene Geräte hinzuzufügen, zu bewahren und zu teilen. 

Azure Spatial Anchors werden im Rahmen der [Unreal-Entwicklungsreise](../unreal/unreal-development-overview.md) behandelt, die den **dringend empfohlenen Pfad für das Erlernen von Mixed Reality mit Unreal** darstellt. Sie befinden sich bereits auf diesem Weg, lesen Sie also einfach weiter, und folgen Sie der großen blauen Schaltfläche am Ende des Artikels. Wenn Sie sich jedoch in einem weiter fortgeschrittenen Lernstadium befinden und bereits wissen, dass Sie fortfahren möchten, sehen Sie sich unsere [Übersicht über Cloud Services](../mixed-reality-cloud-services.md) an, oder wechseln Sie direkt zu den [Dienstressourcen](../unreal/unreal-development-overview.md#5-adding-services).

## <a name="dynamics-365-guides"></a>Dynamics 365-Leitfäden

Sie können **Microsoft Dynamics 365-Leitfäden** verwenden, um holografische Anweisungen visuell mit der virtuellen Umgebung Ihrer Apps zu verknüpfen und Ihren Benutzern wichtige Informationen zu geben, wann und wo sie gebraucht werden. Dieses Feature ist auch in der Unreal-Entwicklungsreise Thema, wenn Sie aber einen Blick in die Zukunft werfen möchten, können Sie sich ansehen, was zur Wahl steht, indem Sie [hier](../unreal/unreal-development-overview.md#5-adding-services) die **Dynamics 365**-Registerkarte auswählen.

## <a name="examples"></a>Beispiele

* [Kippy's Escape](../unreal/unreal-kippys-escape.md): Kippy’s Escape ist eine Open Source-Beispiel-App für HoloLens 2, die mit Unreal Engine 4 und Mixed Reality UX Tools für Unreal erstellt wurde. Das Spiel führt die einzigartigen Features der HoloLens 2-Hardware und die Entwicklungsleistung der Mixed Reality UX Tools vor.


# <a name="javascript"></a>[JavaScript](#tab/web)

![Web](../images/javascript_logo_banner.png)

Die Geräte-API von WebXR ist eine offene Spezifikation, die es Ihnen ermöglicht, Mixed Reality-Apps in Ihrem Browser auf beliebigen Plattformen zu erleben. Informationen zu den ersten Schritten beim Entwickeln von Mixed Reality-Apps für beliebige Plattformen finden Sie in der [JavaScript-Entwicklungsübersicht](../javascript/javascript-development-overview.md).


# <a name="native-openxr"></a>[Nativ (OpenXR)](#tab/native)

 ![Systemeigen](../images/native_logo_banner.png)

Erstellen Sie Mixed Reality-Apps mit einer direkten Verbindung zu den Windows Mixed Reality-APIs. Lesen Sie die [Native Entwicklung – Übersicht](../native/directx-development-overview.md), um in die Entwicklung einer nativen App für HoloLens 2 oder für immersive Headsets für Windows Mixed Reality mithilfe von OpenXR oder Legacy-WinRT einzusteigen. Die Windows Mixed Reality-API unterstützt Anwendungen, die in C++ und C# geschrieben sind, was Ihnen ermöglicht, Ihr eigenes Framework oder eine Middleware in beiden Sprache zu erstellen.

## <a name="available-hardware-platforms"></a>Verfügbare Hardwareplattformen

Bei der Erstellung von Mixed Reality-Apps mit der OpenXR-Entwicklung stehen Ihnen mehrere Hardware-, Emulator- und Streamingoptionen zur Verfügung. 

**Augmented Reality-Geräte**
* [HoloLens 2](/hololens/hololens2-hardware)

**Immersive Headsets (VR)**
* HP Reverb und Reverb G2
* Samsung Odyssey und Odyssey+
* HP Windows Mixed Reality-Headset
* Lenovo-Explorer
* Acer AH101
* Dell Visor
* Asus HC102
* Acer OJO 500

## <a name="available-tools-and-sdks"></a>Verfügbare Tools und SDKs

|  Tool/SDK  |  Beschreibung  |
| --- | --- |
| [OpenXR-Entwicklertools](../native/openxr-getting-started.md#getting-the-openxr-developer-tools-for-windows-mixed-reality) | Bietet eine Demoszene, die verschiedene Features von OpenXR demonstriert, zusammen mit einer Seite „Systemstatus“, auf der Sie wichtige Informationen zur aktiven Laufzeit und zum aktuellen Headset vorfinden. |
| [OpenXR-Spezifikationen](https://www.khronos.org/registry/OpenXR/specs/1.0/html/xrspec.html) |  Beschreibt, was OpenXR ist, welche Funktionen und Features es bietet, und wie Sie es in Ihre eigenen Projekte implementieren können. |
| [OpenXR-Ladeprogramm](../native/openxr-getting-started.md#integrate-the-openxr-loader-into-a-project) | Ermittelt die aktive OpenXR-Laufzeit auf dem Gerät und bietet Zugriff auf die Hauptfunktionen und Erweiterungsfunktionen, die davon implementiert werden. |

## <a name="examples"></a>Beispiele

Sie können gerne mit der Beispiel-App experimentieren, um ein Gefühl für die Möglichkeiten zu bekommen, die Sie mit nativer Entwicklung und Mixed Reality haben.

<!-- Go to actual GH link for more samples -->
* [BasicXrApp](https://github.com/microsoft/OpenXR-MixedReality/tree/master/samples/BasicXrApp) zeigt ein einfaches OpenXR-Beispiel mit zwei Visual Studio-Projektdateien, eine für eine Win32-Desktop-App und eine für eine UWP HoloLens 2-App.

Außerdem können Sie eine einstündige exemplarische Vorgehensweise zu BasicXrApp ansehen, in der alle Schlüsselkomponenten der OpenXR-API in Visual Studio behandelt werden:
>[!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/OpenXR-Cross-platform-native-mixed-reality/player?format=ny]
