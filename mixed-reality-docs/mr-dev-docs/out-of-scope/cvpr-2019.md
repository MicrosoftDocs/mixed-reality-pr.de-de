---
title: Maschinelles Sehen Anwendungen für den Mixed Reality-Headsets-Workshop bei CVPR 2019
description: Übersicht und Zeitplan des Maschinelles Sehen Anwendungen für den Remix-Workshop für gemischte Realität, die auf der CVPR-Konferenz am 2019. Juni geliefert werden.
author: fbogo
ms.author: febogo
ms.date: 1/9/2019
ms.topic: article
keywords: Event, Research Mode, CVPR, Maschinelles sehen, Forschung, hololens
ms.openlocfilehash: 55fbeea1f1293c7df5eae489b6504851bf6bca7f
ms.sourcegitcommit: 09599b4034be825e4536eeb9566968afd021d5f3
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 10/03/2020
ms.locfileid: "91687110"
---
# <a name="computer-vision-applications-for-mixed-reality-headsets"></a><span data-ttu-id="54807-104">Maschinelles Sehen von Anwendungen für Mixed Reality-Headsets</span><span class="sxs-lookup"><span data-stu-id="54807-104">Computer Vision Applications for Mixed Reality Headsets</span></span>

<span data-ttu-id="54807-105">Organisiert in Verbindung mit [CVPR 2019](https://cvpr2019.thecvf.com/)</span><span class="sxs-lookup"><span data-stu-id="54807-105">Organized in conjunction with [CVPR 2019](https://cvpr2019.thecvf.com/)</span></span>

<span data-ttu-id="54807-106">Long-Strand (ca)</span><span class="sxs-lookup"><span data-stu-id="54807-106">Long Beach (CA)</span></span>

<span data-ttu-id="54807-107">17. Juni 2019 (Mittag)-Hyatt-Regency F</span><span class="sxs-lookup"><span data-stu-id="54807-107">June 17, 2019 (Afternoon) - Hyatt Regency F</span></span>


## <a name="organizers"></a><span data-ttu-id="54807-108">Organis</span><span class="sxs-lookup"><span data-stu-id="54807-108">Organizers</span></span>
* <span data-ttu-id="54807-109">Marc Pollefeys</span><span class="sxs-lookup"><span data-stu-id="54807-109">Marc Pollefeys</span></span>
* <span data-ttu-id="54807-110">Federica Bogo</span><span class="sxs-lookup"><span data-stu-id="54807-110">Federica Bogo</span></span>
* <span data-ttu-id="54807-111">Johannes Schönberger</span><span class="sxs-lookup"><span data-stu-id="54807-111">Johannes Schönberger</span></span>
* <span data-ttu-id="54807-112">Osman Ulusoy</span><span class="sxs-lookup"><span data-stu-id="54807-112">Osman Ulusoy</span></span>

## <a name="overview"></a><span data-ttu-id="54807-113">Übersicht</span><span class="sxs-lookup"><span data-stu-id="54807-113">Overview</span></span>

![Teaser-Bild](images/cvpr2019_teaser2.jpg)

<span data-ttu-id="54807-115">Gemischte Reality-Headsets, wie z. b. Microsoft hololens, werden zu leistungsfähigen Plattformen, um maschinelles sehen-Anwendungen</span><span class="sxs-lookup"><span data-stu-id="54807-115">Mixed reality headsets such as the Microsoft HoloLens are becoming powerful platforms to develop computer vision applications.</span></span> <span data-ttu-id="54807-116">Der hololens Research-Modus ermöglicht Maschinelles sehen auf Geräten durch die Bereitstellung von Zugriff auf alle Rohbild-Sensordaten Ströme, einschließlich der Tiefe und der IR.</span><span class="sxs-lookup"><span data-stu-id="54807-116">HoloLens Research Mode enables computer vision research on device by providing access to all raw image sensor streams -- including depth and IR.</span></span> <span data-ttu-id="54807-117">Da der Research-Modus jetzt seit dem 2018 von Mai verfügbar ist, beginnen wir mit der Entwicklung einiger interessanter Demos und Anwendungen, die für hololens entwickelt werden.</span><span class="sxs-lookup"><span data-stu-id="54807-117">As Research Mode is now available since May 2018, we are starting to see several interesting demos and applications being developed for HoloLens.</span></span> 

<span data-ttu-id="54807-118">Das Ziel dieses Workshops besteht darin, Studenten und Forscher zusammenzubringen, die an der Maschinelles sehen für gemischte Reality-Anwendungen interessiert sind.</span><span class="sxs-lookup"><span data-stu-id="54807-118">The goal of this workshop is to bring together students and researchers interested in computer vision for mixed reality applications.</span></span> <span data-ttu-id="54807-119">Der Workshop stellt einen Veranstaltungsort für die gemeinsame Nutzung von Demos und Anwendungen bereit und erfährt von einander, um Anwendungen zu entwickeln oder zu portieren.</span><span class="sxs-lookup"><span data-stu-id="54807-119">The workshop will provide a venue to share demos and applications, and learn from each other to build or port applications to mixed reality.</span></span> 

<span data-ttu-id="54807-120">Wir empfehlen Übermittlungen zu den Themen der (egozentrischen) Objekterkennung, Hand-und Benutzer Nachverfolgung, Aktivitäts Erkennung, Slam, 3D-Rekonstruktion, Szenen Verständnis, sensorbasierte Lokalisierung, Navigation und mehr.</span><span class="sxs-lookup"><span data-stu-id="54807-120">We encourage submissions on the topics of (ego-centric) object recognition, hand and user tracking, activity recognition, SLAM, 3D reconstruction, scene understanding, sensor-based localization, navigation and more.</span></span>

## <a name="paper-submission"></a><span data-ttu-id="54807-121">Papier Übermittlung</span><span class="sxs-lookup"><span data-stu-id="54807-121">Paper Submission</span></span>
* <span data-ttu-id="54807-122">Stichtag für Papier Übermittlung: 17. Mai</span><span class="sxs-lookup"><span data-stu-id="54807-122">Paper submission deadline: May 17</span></span>
* <span data-ttu-id="54807-123">Benachrichtigung an Autoren: 24. Mai</span><span class="sxs-lookup"><span data-stu-id="54807-123">Notification to authors: May 24</span></span>

<span data-ttu-id="54807-124">Für Papier Übermittlungen sollte die CVPR-Vorlage verwendet werden, und Sie sind auf vier Seiten plus Verweise beschränkt.</span><span class="sxs-lookup"><span data-stu-id="54807-124">Paper submissions should use the CVPR template and are limited to 4 pages plus references.</span></span> <span data-ttu-id="54807-125">Außerdem empfehlen wir den Autoren, ein Video zu übermitteln, in dem Ihre Anwendung vorgestellt wird.</span><span class="sxs-lookup"><span data-stu-id="54807-125">In addition, we encourage the authors to submit a video showcasing their application.</span></span>
<span data-ttu-id="54807-126">Beachten Sie, dass Übermittlungen bereits veröffentlichter Arbeit zulässig sind (einschließlich der Arbeit, die an die Hauptkonferenz CVPR 2019 akzeptiert wird).</span><span class="sxs-lookup"><span data-stu-id="54807-126">Note that submissions of previously published work are allowed (including work accepted to the main CVPR 2019 conference).</span></span> 

<span data-ttu-id="54807-127">Einsendungen können auf das CMT hochgeladen werden: https://cmt3.research.microsoft.com/CVFORMR2019</span><span class="sxs-lookup"><span data-stu-id="54807-127">Submissions can be uploaded to the CMT: https://cmt3.research.microsoft.com/CVFORMR2019</span></span>

<span data-ttu-id="54807-128">Im Workshop wird eine Teilmenge der Dokumente zur mündlichen Präsentation ausgewählt.</span><span class="sxs-lookup"><span data-stu-id="54807-128">A subset of papers will be selected for oral presentation at the workshop.</span></span> <span data-ttu-id="54807-129">Wir empfehlen jedoch allen Autoren dringend, ihre Arbeit während der Demo Sitzung zu präsentieren.</span><span class="sxs-lookup"><span data-stu-id="54807-129">However, we strongly encourage all the authors to present their work during the demo session.</span></span>


## <a name="schedule"></a><span data-ttu-id="54807-130">Zeitplan</span><span class="sxs-lookup"><span data-stu-id="54807-130">Schedule</span></span>
* <span data-ttu-id="54807-131">13:30-13:45: Begrüßungs-und Öffnungs Hinweise.</span><span class="sxs-lookup"><span data-stu-id="54807-131">13:30-13:45: Welcome and Opening Remarks.</span></span>
* <span data-ttu-id="54807-132">13:45-14:15: **Keynote Talk** : Prof. Marc Pollefeys, ETH Zürich/Microsoft.</span><span class="sxs-lookup"><span data-stu-id="54807-132">13:45-14:15: **Keynote talk** : Prof. Marc Pollefeys, ETH Zurich/Microsoft.</span></span> <span data-ttu-id="54807-133">Title: egozentrische Maschinelles sehen auf hololens.</span><span class="sxs-lookup"><span data-stu-id="54807-133">Title: Egocentric Computer Vision on HoloLens.</span></span>
* <span data-ttu-id="54807-134">14:15-14:45: **Keynote Talk** : Prof. Kris Kitani, Carnegie Mellon University.</span><span class="sxs-lookup"><span data-stu-id="54807-134">14:15-14:45: **Keynote talk** : Prof. Kris Kitani, Carnegie Mellon University.</span></span> <span data-ttu-id="54807-135">Title: die egozentrische Aktivität und das darstellen von Vorhersagen.</span><span class="sxs-lookup"><span data-stu-id="54807-135">Title: Egocentric Activity and Pose Forecasting.</span></span>
* <span data-ttu-id="54807-136">14:45-15:15: **Keynote Talk** : Dr. Yang Liu, California Institute of Technology.</span><span class="sxs-lookup"><span data-stu-id="54807-136">14:45-15:15: **Keynote talk** : Dr. Yang Liu, California Institute of Technology.</span></span> <span data-ttu-id="54807-137">Title: Schalten Sie einen Cognitive Assistant für blind mit erweiternde Realität ein.</span><span class="sxs-lookup"><span data-stu-id="54807-137">Title: Powering a Cognitive Assistant for the Blind with Augmented Reality.</span></span>
* <span data-ttu-id="54807-138">15:15-16:15: Kaffeepause und Demos.</span><span class="sxs-lookup"><span data-stu-id="54807-138">15:15-16:15: Coffee break and demos.</span></span>
* <span data-ttu-id="54807-139">16:15-16:45: **Keynote Talk** : Prof. Kristen Grauman, University of Texas bei Austin/Facebook AI Research.</span><span class="sxs-lookup"><span data-stu-id="54807-139">16:15-16:45: **Keynote talk** : Prof. Kristen Grauman, University of Texas at Austin/Facebook AI Research.</span></span> <span data-ttu-id="54807-140">Title: Interaktion von Menschen Objekten im Video der ersten Person.</span><span class="sxs-lookup"><span data-stu-id="54807-140">Title: Human-object interaction in first-person video.</span></span>
* <span data-ttu-id="54807-141">16:45-17:15: mündliche Präsentationen:</span><span class="sxs-lookup"><span data-stu-id="54807-141">16:45-17:15: Oral presentations:</span></span>
    * <span data-ttu-id="54807-142">Die Registrierung machte eine einfache, orthopädische Navigation mit hololens.</span><span class="sxs-lookup"><span data-stu-id="54807-142">Registration made easy - standalone orthopedic navigation with HoloLens.</span></span> <span data-ttu-id="54807-143">F.</span><span class="sxs-lookup"><span data-stu-id="54807-143">F.</span></span> <span data-ttu-id="54807-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. snebeker, M. Farshad, P. furnstahl.</span><span class="sxs-lookup"><span data-stu-id="54807-144">Liebmann, S. Roner, M. von Atzigen, F. Wanivenhaus, C. Neuhaus, J. Spirig, D. Scaramuzza, R. Sutter, J. Snedeker, M. Farshad, P. Furnstahl.</span></span>
    * <span data-ttu-id="54807-145">Erlernen von Stereo durchlaufen mit einem hololens.</span><span class="sxs-lookup"><span data-stu-id="54807-145">Learning stereo by walking around with a HoloLens.</span></span> <span data-ttu-id="54807-146">H.</span><span class="sxs-lookup"><span data-stu-id="54807-146">H.</span></span> <span data-ttu-id="54807-147">Zhan, Y. Peer. PEP, O. Ulusoy.</span><span class="sxs-lookup"><span data-stu-id="54807-147">Zhan, Y. Pekelny, O. Ulusoy.</span></span>
* <span data-ttu-id="54807-148">17:15-17:30: Abschließende Hinweise.</span><span class="sxs-lookup"><span data-stu-id="54807-148">17:15-17:30: Final Remarks.</span></span>
