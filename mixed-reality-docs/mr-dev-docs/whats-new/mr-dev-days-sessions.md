---
title: Gemischte Reality dev Days-Sitzungs Aufzeichnungen
description: Seite "Sitzung" mit Video Links für die Entwicklungstage von Mr
author: jessemcculloch
ms.author: jemccull
ms.date: 02/21/2020
ms.topic: article
keywords: Gemischte Realität, Konferenz, Summit, Entwickler, hololens, hololens 2, kinect
ms.openlocfilehash: 53ae80a8a69ad50d85c2b3e193f7baa0c2cbd0e3
ms.sourcegitcommit: 8d3b84d2aa01f078ecf92cec001a252e3ea7b24d
ms.translationtype: MT
ms.contentlocale: de-DE
ms.lasthandoff: 12/23/2020
ms.locfileid: "97757489"
---
# <a name="session-details-and-recordings"></a>Sitzungsdetails und-Aufzeichnungen

![Mixed Reality Dev Days](images/MRDD/MRDevDaysBanner.png)

|**Sitzungs Titel**|**Referent**|**Beschreibung**|
|---------|---------|---------|
|[Öffnende Keynote](https://aka.ms/MRDDKeynote)|Alex Kipman|Alex Kipman startet unser erstes Ereignis für dev Days (dev Days).|
|[Einführung in Azure Mixed Reality-Dienste: Azure-Remote Rendering](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Azure-Mixed-Reality-Services-Azure-Remote-Rendering)|Jonathan Lyons, Christopher Manthei und Marc appelsmeier|Azure-Remote Rendering wurde soeben als öffentliche Vorschauversion eingegeben.  Erfahren Sie, wie arr interaktive 3D-Modelle mit Hunderten von Millionen von Polygonen auf Geräten wie hololens 2 in Echtzeit rendert und streamt.|
|[Einführung in Unreal + mrtk für hololens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Unreal--MRTK-for-HoloLens-2)|Sommer Wu & Luis Valverde|Unreal Engine-Unterstützung für hololens 2 hat den Produktionsstatus mit der Veröffentlichung von UE 4,25 im Mai erreicht! Als Antwort auf die erste Frage, die wir von Entwicklern seit dem ersten Mal in der Vorschauversion von Unreal hololens erhalten haben, veröffentlichte unser Team die erste Komponente des Mixed Reality Toolkit für Unreal: UX Tools 0,8.4,25 In diesem Gespräch geben wir einen Überblick über die Features von Unreal Engine 4 und mrtk für Unreal und erfahren, wie Sie Sie zum Erstellen von epic-Erfahrungen für hololens 2 verwenden.|
|[Die ersten Schritte mit den hololens 2 und Unity](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Getting-started-with-the-HoloLens-2-and-Unity)|Dan Miller-Unity|Erfahren Sie mehr über die Grundlagen der Einrichtung von Unity und der Erstellung für die hololens 2. Diese Präsentation behandelt bewährte Methoden, grundlegende Features der hololens 2 und erläutert, wie Sie mithilfe nativer Unity-APIs schnell Hand Verfolgungs Unterstützung und Interaktivität hinzufügen können.|
|[Einführung in Azure Mixed Reality-Dienste: räumliche Azure-Anker](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-Azure-Mixed-Reality-Services-Azure-Spatial-Anchors)|Archana Iyer & Vicente Rivera|Eine Übersicht über Azure Spatial Anchor (ASA) und relevante Szenarien. In diesem Gespräch werden neue Funktionen erläutert, die im vergangenen Jahr entwickelt wurden, mit Codebeispielen zur Verwendung. Wir überprüfen die bewährten Methoden beim Aufbau mit ASA und erfahren, wie Sie diese in Ihre Produkte integrieren können.|
|[Einführung zu mrtk-Unity](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Intro-to-MRTK-Unity)|Catherine Diaz|Die Einführung in die mrtk-Sitzung ist ein Tutorial zum Erstellen einer mrtk-APP von Anfang bis Ende.  In diesem Gespräch werden Interaktionskonzepte behandelt und die Funktionen der mehrstufigen Plattform von mrtk angezeigt.|
|[Erkenntnisse von der App "Mr-Oberflächen"](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Learnings-from-the-MR-Surfaces-App)|Lars Simkins|Nehmen Sie an den Entwicklern hinter der mrdl-Oberflächen-App für hololens 2 Teil, da Sie über die Entwurfs Story der APP und technische Highlights sprechen.|
|[Unity-Integration in Azure kinect Body Tracking](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Azure-Kinect-Body-Tracking-Unity-Integration)|Angus Antley| Erfahren Sie, wie Sie mit dem Azure kinect-textüberwachungs-SDK Zeichen in Unity verwenden.|
|[Die UX-Bausteine von mrtk](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTKs-UX-Building-Blocks)|Yoon Park|Ausführliche Informationen zu den UX-Komponenten von mrtk, die Ihnen helfen, schöne gemischte Umgebungen zu entwickeln.|
|[Mrtk-Leistungs Tools](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Performance-and-Shaders)|Kurtis Eveleigh & David Kline|Eine Einführung in die Leistungs Tools, sowohl in mrtk als auch extern, und eine Übersicht über den mrtk-Standard-Shader.|
|[Der Zustand der gemischten Realität, in der Unternehmen Erfolg finden](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/The-State-of-Mixed-Reality-Where-Companies-are-finding-Success)|Ori-Amiga & Matt Fleckenstein|Edge Computing mit ultraniedriger Latenz, gekoppelt mit Ki und gemischter Realität, ist die Grundlage für die nächste Generation von Erfahrungen. Durch die Kombination der digitalen und der physischen Welt in universelle Computingumgebungen besteht gemischte Realität darin, Möglichkeiten zu schaffen, von denen wir bisher nur träumen konnten. In dieser Sitzung bieten Ori und Matt einzigartige Einblicke in die Marktchancen für die gemischte Realität heute und in der Zukunft. Sie werden herausfinden, wie Microsoft führenden Unternehmen in der Produktion, der Gesundheitswesen und dem Einzelhandel dabei helfen soll, die Leistung gemischter Realität zu fördern, um Geschäftseffizienz zu fördern und Kunden-und Mitarbeiter Erfahrungen|
|[Fireside Chat](https://aka.ms/MRDDFireside)|Alex Kipman & René Schulte|Öffnen des ersten Tags wir haben Microsoft MVP, Regional Director und das Community-Mitglied extraordinaire René Schulte eingeladen, einen Feuer zu stellen und mit den Themen zu kommunizieren, an denen die Community interessiert ist. René hat seit ungefähr einer Woche Fragen von der Community erhalten, und wir gehen davon aus, dass es sich um eine großartige Konversation handelt.|
|[Entwerfen von AR/VR-Erfahrungen mit Microsoft Maquette](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Designing-ARVR-experiences-using-Microsoft-Maquette)|Ricardo Acosta|Das Entwerfen einer Phone-APP oder einer Website hat einen gut definierten Workflow. Leider kann das Entwerfen räumlicher Realität schwierig sein, wenn Sie den gleichen 2D-Workflow oder das gleiche Toolset verwenden. Glücklicherweise konzentriert sich die neue Microsoft Maquette-App auf die Unterstützung von UX-Designern bei der Entwicklung.|
|[Mrtk Unity v2 & darüber hinaus: wie Community-Feedback uns bei der Verbesserung von mrtk geholfen hat](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/MRTK-Unity-v2-and-beyond-How-community-feedback-helped-us-improve-MRTK)|Bernadette Thalhammer|In diesem Thema wird erläutert, wie wir die Entwickler Erfahrung im letzten Jahr verbessert haben, indem wir uns Feedback aus der Community und wie Entwickler diese Verbesserungen nutzen können. Wir werden uns mit der Dokumentation und Komponententests, der neuen objektmanipulatorkomponente, mithilfe des Migrations Fensters beschäftigen und einige Code Ausschnitte zu den am häufigsten gestellten Fragen der dev-Community untersuchen.|
|[Das Unreal Engine-Plug-in von Dark Slope für das Azure kinect-DK](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Dark-Slopes-Unreal-Engine-plugin-for-the-Azure-Kinect-DK)|Ben unwertvoll-dunkles Steigung|Erfahren Sie, wie die dunkle Neigung das Azure kinect-DK und seine SDKs verwendet, um interaktive Echt Zeit Engagements in der Unreal Engine zu erstellen.|
|[Die Einführung von stereokit-Mr ist einfach!](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Introducing-StereoKit-MR-Made-Easy)|Nick Klingensmith|Stereokit ist eine einfach zu verwendende Open Source-Bibliothek für gemischte Realität zum Entwickeln von hololens und VR-Anwendungen mit c# und openxr! Stereokit priorisiert die Entwicklung gemischter Reality-Anwendungen über alle anderen Elemente, sodass Features wie ein erstklassiges gemischtes Reality-Eingabe System, eine schnelle Leistung standardmäßig auch auf mobilen Geräten, die schnelle Iteration auf dem Gerät und eine Lauf Zeit Medienobjekt-Pipeline, mit der Benutzer und Entwickler echte Ressourcen aus dem Dateisystem laden können. All dies ist in einer knappe-API verpackt, die gut dokumentiert, leicht zu erlernen und leicht zu schreiben ist.|
|[Entwickeln von immersiven Oberflächen für die Erfahrung mit Babylon.js und webxr](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Building-Immersive-MR-Experiences-with-Babylonjs-and-WebXR)|Jason Carter & Raanan Weber|Entdecken Sie, wie einfach und leistungsfähig es sein kann, Mr-Erlebnisse direkt im Web zu entwickeln. Babylon.js ist bestrebt, eine der leistungsfähigsten, einfachsten, einfachen und offenen webrenderingplattformen auf der ganzen Welt zu sein. dadurch ist es ganz einfach, vollständige Funktionen von Mr für Plattformen, Geräte und Ökosysteme freizugeben. Sehen Sie sich die neuesten Entwicklungen Babylon.js und die Unterstützung von webxr an.|
|[Verwenden der Projekt Akustik mit hololens 2](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Using-Project-Acoustics-with-HoloLens-2)|Mike chemistruck|Sehen Sie sich an, wie die Projekt Akustik, die bisher nur für VR-und Konsolentitel verfügbar war, auf gemischte Realität angewendet werden kann! Erfahren Sie, wie das System reale Effekte, wie z. b. die diffraerte oksion und die Umleitung von Sounds um physische Türen und Ecken, und die nach hallung in komplexen Geometrien mit mehreren verbundenen Leerräume neu erstellt, alle innerhalb des computebudgets von hololens 2.|
|[Holographic Remoting-schnelles iterations & übergeordnete Grafiken in hololens](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Holographic-Remoting-Rapid-iteration-and-superharged-graphics-on-HoloLens)|Brent Jackson|Hololens bietet eine revolutionäre Mobile Computing-Plattform, wie keine andere, Sie ist jedoch auf die Verarbeitungsleistung eines mobilen Geräts beschränkt. Holographic Remoting bringt die Rohdaten eines von VR fähigen Computers in hololens, und mit Unity-Editor-Remoting müssen Sie Ihre apps nicht mehr erstellen und bereitstellen, um Sie auf einem Gerät zu testen. Erfahren Sie, wie Sie mit Holographic Remoting die Leistung Ihrer Anwendungen und ihrer Entwickler steigern können.|
|[Openxr auf hololens 2: plattformübergreifende Native gemischte Realität](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/OpenXR-on-HoloLens-2-Cross-platform-native-mixed-reality)|Alex Turner|Openxr 1,0 ist da! Entwickeln Sie von Grund auf eine gemischte Reality-Unterstützung in ihrer eigenen Engine oder systemeigenen App? Wenn dies der Fall ist, erfahren Sie mehr über die wichtigsten Details der nativen openxr-API-Oberfläche, die Erweiterungen, die den vollständigen Satz von hololens 2 zum Leben bringen, und die Partner von Firefox Reality zu stereokit, die bereits auf openxr basierende apps und Frameworks versenden! Mit openxr können Sie herstellerübergreifende gemischte Reality-Engines und Native Apps erstellen, die die Bandbreite der Geräte in der Branche abdecken!|
|[Tipps aus einem Jahr der hololens 2-Entwicklung](https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Tips-from-a-Year-of-HoloLens-2-Development)|Peter Vale|Das hololens-Vermarktungs Team gibt Tipps und Lektionen weiter, die Sie aus dem vergangenen Jahr zusammen mit unseren Partnern gelernt haben.  Verschaffen Sie sich Einblicke in die häufigsten Probleme sowie bewährte Methoden und Techniken, die Sie verwenden können, um Ihre hololens 2-Anwendung für die Freigabe mit ihren Kunden vorzubereiten.|
|||||

--- 
